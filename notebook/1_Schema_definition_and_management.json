{
	"name": "1_Schema_definition_and_management",
	"properties": {
		"folder": {
			"name": "final"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "621db0fb-a371-4b1c-8282-389641377e77"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"mssparkutils.notebook.run('4 - MSSpark Utilities/6 - Mount configuration')"
				],
				"execution_count": 2
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## - Accessing the Files from Mountpoint \r\n",
					"## Syntax:\r\n",
					"# synfs:/<jobid>/<mountpoint>/<path>\r\n",
					"# To get JobID - mssparkutils.env.getJobId()\r\n",
					"\r\n",
					"\r\n",
					"job_id = mssparkutils.env.getJobId()\r\n",
					"\r\n",
					"mount_point = 'synfs:/' + job_id + '/lake'"
				],
				"execution_count": 3
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Read the dataframe\r\n",
					"\r\n",
					"df = spark.read.format('parquet')\\\r\n",
					"                .load(mount_point+'/DateFunction/*.parquet')"
				],
				"execution_count": 4
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df.printSchema()"
				],
				"execution_count": 6
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df_Desc = df.describe()"
				],
				"execution_count": 7
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"display(df_Desc)"
				],
				"execution_count": 8
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df_final = df.drop('Aggregation_Level','Data_Accuracy')"
				],
				"execution_count": 9
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"display(df_final)"
				],
				"execution_count": 10
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Importing the functions \r\n",
					"\r\n",
					"from pyspark.sql.types import StructType,StructField,StringType,IntegerType,FloatType,DateType\r\n",
					"\r\n",
					""
				],
				"execution_count": 11
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"\r\n",
					"\r\n",
					"schema = StructType([\r\n",
					"    StructField('Education_Level',StringType()),\r\n",
					"    StructField('Line_Number',IntegerType()),\r\n",
					"    StructField('Year',IntegerType()),\r\n",
					"    StructField('Month',StringType()),\r\n",
					"    StructField('State',StringType()),\r\n",
					"    StructField('Labor_Force',IntegerType()),\r\n",
					"    StructField('Employed',IntegerType()),\r\n",
					"    StructField('Unemployed',IntegerType()),\r\n",
					"    StructField('Industry',StringType()),\r\n",
					"    StructField('Gender',StringType()),\r\n",
					"    StructField('Date_Inserted',DateType()),\r\n",
					"    StructField('UnEmployed_Rate_Percentage',FloatType()),\r\n",
					"    StructField('Min_Salary_USD',IntegerType()),\r\n",
					"    StructField('Max_Salary_USD',IntegerType()),\r\n",
					"    StructField('dense_rank',IntegerType())\r\n",
					"])"
				],
				"execution_count": 12
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df_new = spark.createDataFrame(df_final.rdd,schema)"
				],
				"execution_count": 13
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df_new.printSchema()"
				],
				"execution_count": 14
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"display(df_new)"
				],
				"execution_count": 15
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"Reading Window FUnction dataframe to test date field"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Read the dataframe\r\n",
					"\r\n",
					"df_window = spark.read.format('parquet')\\\r\n",
					"                .load(mount_point+'/WindowFunctions/*.parquet')"
				],
				"execution_count": 16
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df_window.printSchema()"
				],
				"execution_count": 17
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df_window = df_window.drop('Aggregation_Level','Data_Accuracy')"
				],
				"execution_count": 18
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df_window.printSchema()"
				],
				"execution_count": 19
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"schema1 = StructType([\r\n",
					"    StructField('Education_Level',StringType()),\r\n",
					"    StructField('Line_Number',IntegerType()),\r\n",
					"    StructField('Year',IntegerType()),\r\n",
					"    StructField('Month',StringType()),\r\n",
					"    StructField('State',StringType()),\r\n",
					"    StructField('Labor_Force',IntegerType()),\r\n",
					"    StructField('Employed',IntegerType()),\r\n",
					"    StructField('Unemployed',IntegerType()),\r\n",
					"    StructField('Industry',StringType()),\r\n",
					"    StructField('Gender',StringType()),\r\n",
					"    StructField('Date_Inserted',StringType()),\r\n",
					"    StructField('UnEmployed_Rate_Percentage',FloatType()),\r\n",
					"    StructField('Min_Salary_USD',IntegerType()),\r\n",
					"    StructField('Max_Salary_USD',IntegerType()),\r\n",
					"    StructField('dense_rank',IntegerType())\r\n",
					"])"
				],
				"execution_count": 25
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df_w = spark.createDataFrame(df_window.rdd,schema1)"
				],
				"execution_count": 26
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"display(df_w)"
				],
				"execution_count": 27
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df_new.write.format('parquet')\\\r\n",
					"            .mode('overwrite')\\\r\n",
					"            .save(mount_point+'/SchemaManagement/')"
				],
				"execution_count": 28
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					""
				],
				"execution_count": null
			}
		]
	}
}